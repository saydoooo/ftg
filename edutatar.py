# ‚ñà ‚ñà ‚ñÄ ‚ñà‚ñÑ‚ñÄ ‚ñÑ‚ñÄ‚ñà ‚ñà‚ñÄ‚ñà ‚ñÄ    ‚ñÑ‚ñÄ‚ñà ‚ñÄ‚ñà‚ñÄ ‚ñÑ‚ñÄ‚ñà ‚ñà‚ñÄ‚ñÑ‚ñÄ‚ñà ‚ñÑ‚ñÄ‚ñà
# ‚ñà‚ñÄ‚ñà ‚ñà ‚ñà ‚ñà ‚ñà‚ñÄ‚ñà ‚ñà‚ñÄ‚ñÑ ‚ñà ‚ñÑ  ‚ñà‚ñÄ‚ñà  ‚ñà  ‚ñà‚ñÄ‚ñà ‚ñà ‚ñÄ ‚ñà ‚ñà‚ñÄ‚ñà
#
#              ¬© Copyright 2022
#
#          https://t.me/hikariatama
#
# üîí Licensed under the GNU GPLv3
# üåê https://www.gnu.org/licenses/agpl-3.0.html

# meta pic: https://img.icons8.com/fluency/48/000000/dictionary.png
# meta developer: @hikariatama

from .. import loader, utils
import asyncio
import re
import requests
from datetime import datetime, timedelta
import time
from telethon.tl.types import Message


filters = {
    "–ò–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã–π —è–∑—ã–∫ (–∞–Ω–≥–ª–∏–π—Å–∫–∏–π)": "üá∫üá∏ –ê–Ω–≥–ª",
    "–§–∏–∑–∏—á–µ—Å–∫–∞—è –∫—É–ª—å—Ç—É—Ä–∞": "‚õπÔ∏è‚Äç‚ôÇÔ∏è PE",
    "–§–∏–∑–∏–∫–∞": "‚öõÔ∏è –§–∏–∑–æ–Ω",
    "–õ–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞": "üìï –õ–∏—Ç-—Ä–∞",
    "–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞": "üìê Maths",
    "–û—Å–Ω–æ–≤—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∂–∏–∑–Ω–µ–¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏": "üß∞ –û–ë–ñ",
    "–†–æ–¥–Ω–æ–π —è–∑—ã–∫": "üó£ –†–æ–¥–Ω–æ–π",
    "–ò—Å—Ç–æ—Ä–∏—è": "‚öí –ò—Å—Ç–æ—Ä–∏—è",
    "–†–æ–¥–Ω–∞—è –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞": "üìñ –†–æ–¥–Ω.–ª–∏—Ç",
    "–ì–µ–æ–≥—Ä–∞—Ñ–∏—è": "üó∫ –ì–µ–æ",
    "–ò–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞": "üíª IT",
    "–û–±—â–µ—Å—Ç–≤–æ–∑–Ω–∞–Ω–∏–µ": "‚öñÔ∏è –û–±—â–µ—Å—Ç–≤–æ",
    "–†—É—Å—Å–∫–∏–π —è–∑—ã–∫": "‚úçÔ∏è –†—É—Å—Å–∫–∏–π",
    "–•–∏–º–∏—è": "üß™ –•–∏–º–∏—è",
    "–ë–∏–æ–ª–æ–≥–∏—è": "üß¨ –ë–∏–æ",
    "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è": "üî© –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è",
}


@loader.tds
class EduTatarMod(loader.Module):
    """Telegram client for edu.tatar.ru"""

    strings = {
        "name": "eduTatar",
        "login_pass_not_specified": "<b>üîë –ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å –ª–æ–≥–∏–Ω –∏ –ø–∞—Ä–æ–ª—å –æ—Ç edu.tatar.ru –≤ –∫–æ–Ω—Ñ–∏–≥–µ</b>",
        "loading_info": "<b>üë©üèº‚Äçüè´ –ó–∞–≥—Ä—É–∂–∞—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å edu.tatar.ru...</b>",
        "host_error": "üö´ Error occured while parsing. Maybe edutatar host is down or <b>you forgot to change proxy in script</b>?",
        "no_hw": "üìï –ù–µ—Ç –¥\\–∑",
    }

    def __init__(self):
        self.config = loader.ModuleConfig(
            "edu_tatar_login",
            False,
            lambda: "Login from edu.tatar.ru",
            "edu_tatar_pass",
            False,
            lambda: "Password from edu.tatar.ru",
            "marks_parse_delay",
            300,
            lambda: "Delay for parsing new marks in seconds",
            "proxy",
            "",
            lambda: "Proxy for correct work of module",
        )

    async def client_ready(self, client, db):
        self._db = db
        self.sess = {"DNSID": db.get("eduTatar", "sess", None)}
        if self.sess["DNSID"] is None:
            await self.revoke_token()

        self._client = client
        asyncio.ensure_future(self.parse_marks_async())

    async def parse_marks_async(self):
        while True:
            await self.check_marks()
            await asyncio.sleep(self.config["marks_parse_delay"])

    async def eduweekcmd(self, message: Message):
        """Show schedule for a week"""
        if not self.config["edu_tatar_login"] or not self.config["edu_tatar_pass"]:
            await utils.answer(
                message, self.strings("login_pass_not_specified", message)
            )
            await asyncio.sleep(3)
            await message.delete()
            return

        await utils.answer(message, self.strings("loading_info", message))
        data = await self.scrape_week()
        await utils.answer(message, data)

    async def edudaycmd(self, message: Message):
        """<day:integer{0,}> - Show schedule for today"""
        if not self.config["edu_tatar_login"] or not self.config["edu_tatar_pass"]:
            await utils.answer(
                message, self.strings("login_pass_not_specified", message)
            )
            await asyncio.sleep(3)
            await message.delete()
            return

        args = utils.get_args_raw(message)
        if args == "":
            offset = 0

        try:
            offset = abs(int(args))
            offset = offset * 60 * 60 * 24
        except:
            pass

        now = datetime.now()
        today = now - timedelta(hours=now.hour, minutes=now.minute, seconds=now.second)
        day = time.mktime(today.timetuple()) + offset
        day_datetime = datetime.utcfromtimestamp(day)
        await utils.answer(message, self.strings("loading_info", message))
        weekdays = [
            "Monday",
            "Tuesday",
            "Wednesday",
            "Thursday",
            "Friday",
            "Saturday",
            "Sunday",
            "Monday",
        ]
        data = (
            f"üìö <b>{weekdays[day_datetime.weekday() + 1]}</b> üìö\n\n"
            + await self.scrape_date(day)
        )
        await utils.answer(message, data)

    async def edutermcmd(self, message: Message):
        """Get term grades"""
        if not self.config["edu_tatar_login"] or not self.config["edu_tatar_pass"]:
            await utils.answer(
                message, self.string("login_pass_not_specified", message)
            )
            await asyncio.sleep(3)
            await message.delete()
            return

        await utils.answer(message, self.strings("loading_info", message))
        data = await self.scrape_term(utils.get_args_raw(message))
        await utils.answer(message, data)

    async def revoke_token(self):
        try:
            answ = await utils.run_sync(
                requests.post,
                "https://edu.tatar.ru/logon",
                headers={
                    "Host": "edu.tatar.ru",
                    "Connection": "keep-alive",
                    "Content-Length": "52",
                    "Pragma": "no-cache",
                    "Cache-Control": "no-cache",
                    "Upgrade-Insecure-Requests": "1",
                    "Origin": "https://edu.tatar.ru",
                    "Content-Type": "application/x-www-form-urlencoded",
                    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36",
                    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9",
                    "Sec-GPC": "1",
                    "Sec-Fetch-Site": "same-origin",
                    "Sec-Fetch-Mode": "navigate",
                    "Sec-Fetch-User": "?1",
                    "Sec-Fetch-Dest": "document",
                    "Referer": "https://edu.tatar.ru/logon",
                    "Accept-Encoding": "gzip, deflate, br",
                    "Accept-Language": "en-US,en;q=0.9",
                },
                data={
                    "main_login2": self.config["edu_tatar_login"],
                    "main_password2": self.config["edu_tatar_pass"],
                },
                allow_redirects=True,
                proxies={"https": self.config["proxy"]},
            )
        except requests.exceptions.ProxyError:
            return self.strings("host_error")

        if "DNSID" in dict(answ.cookies):
            self.sess = dict(answ.cookies)
        else:
            raise ValueError("Failed logging in")

        self._db.set("eduTatar", "sess", self.sess["DNSID"])

    async def check_marks(self):
        marks_tmp = self._db.get("eduTatar", "marks", {}).copy()
        await self.scrape_term("")
        marks_new = self._db.get("eduTatar", "marks", {}).copy()
        for subject, current_marks_2 in list(marks_new.items()):
            current_marks_1 = [] if subject not in marks_tmp else marks_tmp[subject]
            try:
                subject = filters[subject]
            except KeyError:
                pass

            for i in range(min(len(current_marks_1), len(current_marks_2))):
                if current_marks_1[i] != current_marks_2[i]:
                    await self._client.send_message(
                        "@userbot_notifies_bot",
                        utils.escape_html(
                            f'<b>{subject}: {current_marks_1[i]}->{current_marks_2[i]}\n</b><code>{" ".join(list(map(str, current_marks_2)))}</code>'
                        ),
                    )
                    await asyncio.sleep(0.5)

            for i in range(
                min(len(current_marks_1), len(current_marks_2)), len(current_marks_2)
            ):
                await self._client.send_message(
                    "@userbot_notifies_bot",
                    utils.escape_html(
                        f'<b>{subject}: {current_marks_2[i ]}\n</b><code>{" ".join(list(map(str, current_marks_2)))}</code>'
                    ),
                )
                await asyncio.sleep(0.5)

    async def scrape_date(self, date):
        try:
            answ = await utils.run_sync(
                requests.get,
                "https://edu.tatar.ru/user/diary/day?for=" + str(date),
                cookies=self.sess,
                headers={
                    "Host": "edu.tatar.ru",
                    "Connection": "keep-alive",
                    "Upgrade-Insecure-Requests": "1",
                    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36",
                    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9",
                    "Sec-GPC": "1",
                    "Sec-Fetch-Site": "same-origin",
                    "Sec-Fetch-Mode": "navigate",
                    "Sec-Fetch-User": "?1",
                    "Sec-Fetch-Dest": "document",
                    "Referer": "https://edu.tatar.ru/user/diary/week",
                    "Accept-Encoding": "gzip, deflate, br",
                    "Accept-Language": "en-US,en;q=0.9",
                },
                proxies={"https": self.config["proxy"]},
            )
        except requests.exceptions.ProxyError:
            return self.strings("host_error")

        day = re.findall(
            r"<td style=.vertical.*?>.*?<td style=.vertical.*?middle.*?>(.*?)</td>.*?<p>(.*?)</p>.*?</tr>",
            answ.text.replace("\n", ""),
        )
        if len(day) < 5:
            await self.revoke_token()
            return await self.scrape_date(date)
        ans = ""
        for sub in day:
            hw = sub[1].strip()
            if hw == "":
                hw = self.strings("no_hw")
            subject = sub[0].strip()

            for from_, to_ in filters.items():
                subject = subject.replace(from_, to_)

            ans += f" <b>{subject}</b> - <i>{hw}" + "</i>\n"

        return ans

    async def scrape_week(self):
        now = datetime.now()
        monday = now - timedelta(
            days=now.weekday(), hours=now.hour, minutes=now.minute, seconds=now.second
        )
        monday = time.mktime(monday.timetuple())

        week = ""
        weekdays = ["–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫", "–í—Ç–æ—Ä–Ω–∏–∫", "–°—Ä–µ–¥–∞", "–ß–µ—Ç–≤–µ—Ä–≥", "–ü—è—Ç–Ω–∏—Ü–∞", "–°—É–±–±–æ—Ç–∞"]
        for i in range(6):
            week += f"üìö <b>{weekdays[i]}</b> üìö\n"
            week += await self.scrape_date(monday + 60**2 * 24 * i)

        return week

    async def scrape_term(self, args):
        try:
            answ = await utils.run_sync(
                requests.get,
                "https://edu.tatar.ru/user/diary/term",
                cookies=self.sess,
                headers={
                    "Host": "edu.tatar.ru",
                    "Connection": "keep-alive",
                    "Upgrade-Insecure-Requests": "1",
                    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36",
                    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9",
                    "Sec-GPC": "1",
                    "Sec-Fetch-Site": "same-origin",
                    "Sec-Fetch-Mode": "navigate",
                    "Sec-Fetch-User": "?1",
                    "Sec-Fetch-Dest": "document",
                    "Referer": "https://edu.tatar.ru/user/diary/week",
                    "Accept-Encoding": "gzip, deflate, br",
                    "Accept-Language": "en-US,en;q=0.9",
                },
                proxies={"https": self.config["proxy"]},
            )
        except requests.exceptions.ProxyError:
            return self.strings("host_error")

        term = "<b>={ –¢–∞–±–µ–ª—å —É—Å–ø–µ–≤–∞–µ–º–æ—Å—Ç–∏ }=</b>\n"
        rows = re.findall(
            r"<tr>.*?<td>(.*?)</td>(.*?)</tr>", answ.text.replace("\n", "")
        )
        cols = {}
        for row in rows[1:-1]:
            subject = row[0]
            processing = (
                row[1][: row[1].find("<!--")].replace("<td>", "").replace(" ", "")
            )
            marks_temp = list(filter(lambda a: a != "", processing.split("</td>")))
            marks_tmp = " ".join(marks_temp[:-1])
            marks_db = self._db.get("eduTatar", "marks", {})
            if "-n" in args:
                marks = (
                    str(marks_tmp.count("5"))
                    + " | "
                    + str(marks_tmp.count("4"))
                    + " | "
                    + str(marks_tmp.count("3"))
                    + " | "
                    + str(marks_tmp.count("2"))
                    + " |"
                )
            else:
                marks = marks_tmp

            marks_db[subject] = marks_tmp.split()
            self._db.set("eduTatar", "marks", marks_db)

            marks += (
                " <b>="
                + marks_temp[-1]
                + " | "
                + str(round(float(marks_temp[-1]) + 0.001))
                + "</b>"
            )
            marks = marks.replace("\t", "")
            marks = re.sub(r"[ ]{2,}", "", marks)
            for from_, to_ in filters.items():
                subject = subject.replace(from_, to_)
            cols[subject] = marks

        try:
            maxelem = max(
                list(map(len, list(map(lambda a: a.split(" ")[1], list(cols.keys())))))
            )
            maxelem_val = max(
                list(
                    map(
                        len,
                        list(map(lambda a: a.split("<b>", 1)[0], list(cols.values()))),
                    )
                )
            )
        except ValueError:
            time.sleep(5)
            return await self.scrape_term(args)
        # print(maxelem)
        offset = " " * (maxelem - 7)
        if "-n" in args:
            term += (
                f"<code>  Subject{offset}   5 | 4 | 3 | 2 | Result</code>\n<code>"
                + ("=" * (maxelem - 7 + 33))
                + "</code>\n"
            )
        else:
            term += "\n"

        for sub, marks in cols.items():
            offset = " " * (maxelem - len(sub.split(" ")[1]))
            offset_val = " " * (maxelem_val - len(marks.split("<b>", 1)[0]))
            term += f'<code>{sub}:{offset} {marks.split("<b>", 1)[0]}{offset_val}</code><b>{marks.split("<b>", 1)[1]}\n'

        return term
